services:
  # Ollama - Model runtime and API
  ollama:
    container_name: ollama
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    mem_limit: "12g"
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_MODELS=/models/ollama
      - OLLAMA_NUM_THREADS=6
      - OLLAMA_NUM_PARALLEL=1
    volumes:
      - ./models:/models
    restart: unless-stopped
    networks:
      - ai-stack-network

  # One-shot init: create models from Modelfiles
  ollama-init:
    container_name: ollama-init
    image: ollama/ollama:latest
    depends_on:
      - ollama
    environment:
      - OLLAMA_HOST=http://ollama:11434
    volumes:
      - ./models:/models
      - ./scripts/ollama-init.sh:/scripts/ollama-init.sh:ro
    entrypoint: ["/bin/sh", "/scripts/ollama-init.sh"]
    restart: "no"
    networks:
      - ai-stack-network

  # LibreChat API
  librechat-api:
    container_name: LibreChat
    image: ghcr.io/danny-avila/librechat-dev:latest
    ports:
      - "${PORT:-3080}:${PORT:-3080}"
    depends_on:
      - mongodb
      - rag_api
      - ollama
    restart: always
    user: "${UID:-1000}:${GID:-1000}"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    env_file:
      - LibreChat/.env
    environment:
      - HOST=0.0.0.0
      - PORT=${PORT:-3080}
      - MONGO_URI=mongodb://mongodb:27017/LibreChat
      - MEILI_HOST=http://meilisearch:7700
      - RAG_PORT=${RAG_PORT:-8000}
      - RAG_API_URL=http://rag_api:${RAG_PORT:-8000}
    volumes:
      - type: bind
        source: ./LibreChat/.env
        target: /app/.env
      - type: bind
        source: ./LibreChat/librechat.yaml
        target: /app/librechat.yaml
      - ./LibreChat/images:/app/client/public/images
      - ./LibreChat/uploads:/app/uploads
      - ./LibreChat/logs:/app/logs
    networks:
      - ai-stack-network

  # MongoDB for LibreChat
  mongodb:
    container_name: chat-mongodb
    image: mongo:8.0.17
    restart: always
    volumes:
      - ./LibreChat/data-node:/data/db
    command: mongod --noauth
    networks:
      - ai-stack-network

  # Meilisearch for LibreChat
  meilisearch:
    container_name: chat-meilisearch
    image: getmeili/meilisearch:v1.12.3
    restart: always
    user: "${UID:-1000}:${GID:-1000}"
    environment:
      - MEILI_HOST=http://meilisearch:7700
      - MEILI_NO_ANALYTICS=true
      - MEILI_MASTER_KEY=${MEILI_MASTER_KEY:-changeme-master-key}
    volumes:
      - ./LibreChat/meili_data_v1.12:/meili_data
    networks:
      - ai-stack-network

  # Vector Database for RAG
  vectordb:
    container_name: vectordb
    image: pgvector/pgvector:0.8.0-pg15-trixie
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-mydatabase}
      POSTGRES_USER: ${POSTGRES_USER:-myuser}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-changeme}
    restart: always
    volumes:
      - pgdata2:/var/lib/postgresql/data
    networks:
      - ai-stack-network

  # RAG API for LibreChat
  rag_api:
    container_name: rag_api
    image: ghcr.io/danny-avila/librechat-rag-api-dev-lite:latest
    environment:
      - DB_HOST=vectordb
      - RAG_PORT=${RAG_PORT:-8000}
    restart: always
    depends_on:
      - vectordb
    env_file:
      - LibreChat/.env
    networks:
      - ai-stack-network

  # OpenCode - AI coding agent (TUI)
  # Run with: docker compose run --rm opencode
  opencode:
    container_name: opencode
    build:
      context: ./opencode
      dockerfile: Dockerfile
    environment:
      - TERM=xterm-256color
    volumes:
      - ./opencode/opencode.json:/home/opencode/.config/opencode/opencode.json:ro
      - ./:/workspace
    stdin_open: true
    tty: true
    depends_on:
      - ollama
    profiles:
      - cli
    networks:
      - ai-stack-network

  # OpenCode Daemon - Persistent container for running tasks
  # Start with: docker compose up -d opencode-daemon
  # Run tasks: docker exec opencode-daemon opencode "your task here"
  opencode-daemon:
    container_name: opencode-daemon
    build:
      context: ./opencode
      dockerfile: Dockerfile
    entrypoint: ["/workspace/scripts/entrypoint.sh"]
    command: ["/workspace/scripts/daemon.sh"]
    environment:
      - TERM=xterm-256color
    volumes:
      # Mount entire workspace for persistence
      - ./opencode:/workspace
      # OpenCode config
      - ./opencode/opencode.json:/home/opencode/.config/opencode/opencode.json:ro
      # Timezone
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
    depends_on:
      - ollama
    restart: unless-stopped
    networks:
      - ai-stack-network

volumes:
  pgdata2:

networks:
  ai-stack-network:
    driver: bridge
